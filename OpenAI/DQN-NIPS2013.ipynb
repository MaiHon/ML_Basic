{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN-NIPS2013.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Y7gPpovoeXAy","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import random as rd\n","import gym\n","from collections import deque"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yd4_N-TbfVS4","colab_type":"code","colab":{}},"source":["class DQN:\n","  def __init__(self, sess, input_size, output_size, name=\"main\"):\n","    self.sess = sess\n","    self.input_size = input_size\n","    self.output_size = output_size\n","    self.net_name = name\n","    \n","    self._build_network()\n","  \n","  def _build_network(self, h_size=16, l_rate=1e-3):\n","    with tf.device('/device:GPU:0'):\n","      with tf.variable_scope(self.net_name):\n","        self._x = tf.placeholder(tf.float32, shape=[None, self.input_size], name=\"input_x\")\n","        \n","        W1 = tf.get_variable('W1', shape=[self.input_size, h_size],\n","                              initializer = tf.contrib.layers.xavier_initializer())\n","        L1 = tf.nn.tanh(tf.matmul(self._x, W1))\n","        \n","        W2 = tf.get_variable('W2', shape=[h_size, self.output_size],\n","                              initializer = tf.contrib.layers.xavier_initializer())\n","        self._Qpred = tf.matmul(L1, W2)\n","      \n","      # Need to define the parts of the network needed for learning a\n","      # Policy\n","      self._y = tf.placeholder(shape=[None, self.output_size], dtype=tf.float32)\n","      \n","      # Loss\n","      self._loss = tf.reduce_mean(tf.square(self._y - self._Qpred))\n","      # Training\n","      self._train = tf.train.AdamOptimizer(l_rate, epsilon=1e-5).minimize(self._loss)\n","      \n","  def predict(self, state):\n","    x = np.reshape(state, [-1, self.input_size])\n","    return self.sess.run(self._Qpred, feed_dict = {self._x : x})\n","  \n","  def update(self, x_stack, y_stack):\n","    return self.sess.run([self._loss, self._train],\n","                         feed_dict={self._x: x_stack, self._y: y_stack})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wHMXyqQnvLh","colab_type":"code","colab":{}},"source":["def simple_replay_train(DQN, train_batch):\n","#   x_stack = np.empty(0).reshape(0, DQN.input_size)\n","#   y_stack = np.empty(0).reshape(0, DQN.output_size)\n","  \n","#   # Get stored information from the buffer\n","#   for state, action, reward, next_state, done in train_batch:\n","#     Q = DQN.predict(state)\n","    \n","#     # Terminal?\n","#     if done:\n","#       Q[0, action] = reward\n","#     else:\n","#       Q[0, action] = reward + dis * np.max(DQN.predict(next_state))\n","      \n","#     y_stack = np.vstack([y_stack, Q])\n","#     x_stack = np.vstack([x_stack, state])\n","    \n","#   return DQN.update(x_stack, y_stack)\n","  states = np.vstack([x[0] for x in train_batch])\n","  actions = np.array([x[1] for x in train_batch])\n","  rewards = np.array([x[2] for x in train_batch])\n","  next_states = np.vstack([x[3] for x in train_batch])\n","  done = np.array([x[4] for x in train_batch])\n","\n","  X = states\n","\n","  Q = rewards + dis * np.max(DQN.predict(next_states), axis=1) * ~done\n","\n","  y = DQN.predict(states)\n","  y[np.arange(len(X)), actions] = Q\n","\n","  # Train our network using target and predicted Q values on each episode\n","  return DQN.update(X, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFu_7FuTobKQ","colab_type":"code","colab":{}},"source":["def bot_play(mainDQN):\n","  state = env.reset()\n","  reward_sum = 0\n","  \n","  while True:\n","    env.render()\n","    a = np.argmax(mainDQN.predict(s))\n","    \n","    s, reward, done, _ = env.step(a)\n","    reward_sum += reward\n","    if done:\n","      print(\"Total score: {}\".format(reward_sum))\n","      break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zk2Qg_v-ph5Q","colab_type":"code","colab":{}},"source":["env = gym.make('CartPole-v1')\n","\n","env._max_episode_step = 10001\n","input_size = env.observation_space.shape[0]\n","output_size = env.action_space.n\n","\n","dis = 0.99\n","REPLAY_MEMORY = 50000\n","BATCH_SIZE = 64"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H8Usl-qyovAA","colab_type":"code","colab":{}},"source":["def main():\n","  max_episodes = 5000\n","  \n","  # Store the previous observations in replay memory\n","  replay_buffer = deque(maxlen=REPLAY_MEMORY)\n","  last_100_game_reward = deque(maxlen=100)\n","  \n","  with tf.Session() as sess:\n","    dqn = DQN(sess, input_size, output_size)\n","    tf.global_variables_initializer().run()\n","    \n","    for episode in range(max_episodes):\n","      e = 1. / ((episode + 10) + 1)\n","      done = False\n","      step_cnt = 0\n","      \n","      state = env.reset()\n","      \n","      while not done:\n","        if np.random.rand(1) < e:\n","          action = env.action_space.sample()\n","        else:\n","          # Choose an action by greedily from the Q-net\n","          action = np.argmax(dqn.predict(state))\n","        \n","        # Get new state and reward from environment\n","        next_state, reward, done, _ = env.step(action)\n","        if done:\n","          reward = -100\n","        \n","        # Save the experience to the buffer\n","        replay_buffer.append(\n","               (state, action, reward, next_state, done)\n","        )\n","        \n","        \n","        \n","        state = next_state\n","        step_cnt += 1\n","        if step_cnt > 10000:\n","          break\n","            \n","      print(\"Episode: {}    step: {}\".format(episode, step_cnt))\n","      if step_cnt > 10000:\n","        pass\n","        break\n","    \n","      if episode % 10 == 1 and episode != 1:\n","        # Get a random batch of experiences\n","        for _ in range(50):\n","          # Minibatch works better\n","          minibatch = rd.sample(replay_buffer, 100)\n","          loss, _ = simple_replay_train(dqn, minibatch)\n","        print(\"Loss: \", loss)\n","        \n","  bot_play(dqn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJYp59SW3Czp","colab_type":"code","outputId":"794fab00-587c-4e84-ebe9-6cfb649f0bbf","executionInfo":{"status":"ok","timestamp":1558723917799,"user_tz":-540,"elapsed":3155,"user":{"displayName":"Hong Hong","photoUrl":"","userId":"17352177631675721232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["env._max_episode_step"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10001"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"z6XkKuxZq67x","colab_type":"code","outputId":"6870c181-90f6-44ce-8565-d2c518f40956","executionInfo":{"status":"error","timestamp":1558723957248,"user_tz":-540,"elapsed":42597,"user":{"displayName":"Hong Hong","photoUrl":"","userId":"17352177631675721232"}},"colab":{"base_uri":"https://localhost:8080/","height":5206}},"source":["if __name__ == \"__main__\":\n","  main()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","Episode: 0    step: 10\n","Episode: 1    step: 9\n","Episode: 2    step: 10\n","Episode: 3    step: 10\n","Episode: 4    step: 9\n","Episode: 5    step: 8\n","Episode: 6    step: 8\n","Episode: 7    step: 8\n","Episode: 8    step: 10\n","Episode: 9    step: 9\n","Episode: 10    step: 8\n","Episode: 11    step: 10\n","Loss:  553.3398\n","Episode: 12    step: 10\n","Episode: 13    step: 10\n","Episode: 14    step: 9\n","Episode: 15    step: 10\n","Episode: 16    step: 10\n","Episode: 17    step: 10\n","Episode: 18    step: 10\n","Episode: 19    step: 10\n","Episode: 20    step: 9\n","Episode: 21    step: 9\n","Loss:  493.44067\n","Episode: 22    step: 49\n","Episode: 23    step: 44\n","Episode: 24    step: 59\n","Episode: 25    step: 81\n","Episode: 26    step: 47\n","Episode: 27    step: 61\n","Episode: 28    step: 55\n","Episode: 29    step: 190\n","Episode: 30    step: 187\n","Episode: 31    step: 90\n","Loss:  148.953\n","Episode: 32    step: 81\n","Episode: 33    step: 80\n","Episode: 34    step: 215\n","Episode: 35    step: 218\n","Episode: 36    step: 112\n","Episode: 37    step: 52\n","Episode: 38    step: 81\n","Episode: 39    step: 83\n","Episode: 40    step: 73\n","Episode: 41    step: 63\n","Loss:  51.01751\n","Episode: 42    step: 53\n","Episode: 43    step: 84\n","Episode: 44    step: 130\n","Episode: 45    step: 84\n","Episode: 46    step: 104\n","Episode: 47    step: 60\n","Episode: 48    step: 198\n","Episode: 49    step: 75\n","Episode: 50    step: 60\n","Episode: 51    step: 78\n","Loss:  147.09233\n","Episode: 52    step: 155\n","Episode: 53    step: 49\n","Episode: 54    step: 52\n","Episode: 55    step: 54\n","Episode: 56    step: 101\n","Episode: 57    step: 135\n","Episode: 58    step: 62\n","Episode: 59    step: 45\n","Episode: 60    step: 76\n","Episode: 61    step: 338\n","Loss:  0.5610001\n","Episode: 62    step: 242\n","Episode: 63    step: 100\n","Episode: 64    step: 55\n","Episode: 65    step: 38\n","Episode: 66    step: 165\n","Episode: 67    step: 75\n","Episode: 68    step: 105\n","Episode: 69    step: 49\n","Episode: 70    step: 54\n","Episode: 71    step: 141\n","Loss:  151.11812\n","Episode: 72    step: 120\n","Episode: 73    step: 154\n","Episode: 74    step: 62\n","Episode: 75    step: 205\n","Episode: 76    step: 83\n","Episode: 77    step: 52\n","Episode: 78    step: 40\n","Episode: 79    step: 125\n","Episode: 80    step: 169\n","Episode: 81    step: 142\n","Loss:  0.6177006\n","Episode: 82    step: 44\n","Episode: 83    step: 123\n","Episode: 84    step: 58\n","Episode: 85    step: 54\n","Episode: 86    step: 102\n","Episode: 87    step: 129\n","Episode: 88    step: 50\n","Episode: 89    step: 79\n","Episode: 90    step: 40\n","Episode: 91    step: 53\n","Loss:  96.93238\n","Episode: 92    step: 41\n","Episode: 93    step: 142\n","Episode: 94    step: 47\n","Episode: 95    step: 114\n","Episode: 96    step: 117\n","Episode: 97    step: 58\n","Episode: 98    step: 128\n","Episode: 99    step: 378\n","Episode: 100    step: 41\n","Episode: 101    step: 41\n","Loss:  0.6090836\n","Episode: 102    step: 142\n","Episode: 103    step: 68\n","Episode: 104    step: 164\n","Episode: 105    step: 127\n","Episode: 106    step: 63\n","Episode: 107    step: 84\n","Episode: 108    step: 67\n","Episode: 109    step: 128\n","Episode: 110    step: 69\n","Episode: 111    step: 126\n","Loss:  100.59798\n","Episode: 112    step: 49\n","Episode: 113    step: 80\n","Episode: 114    step: 66\n","Episode: 115    step: 62\n","Episode: 116    step: 257\n","Episode: 117    step: 36\n","Episode: 118    step: 43\n","Episode: 119    step: 49\n","Episode: 120    step: 66\n","Episode: 121    step: 42\n","Loss:  0.5652003\n","Episode: 122    step: 42\n","Episode: 123    step: 74\n","Episode: 124    step: 46\n","Episode: 125    step: 47\n","Episode: 126    step: 136\n","Episode: 127    step: 222\n","Episode: 128    step: 106\n","Episode: 129    step: 166\n","Episode: 130    step: 52\n","Episode: 131    step: 61\n","Loss:  50.599014\n","Episode: 132    step: 56\n","Episode: 133    step: 82\n","Episode: 134    step: 79\n","Episode: 135    step: 42\n","Episode: 136    step: 67\n","Episode: 137    step: 88\n","Episode: 138    step: 48\n","Episode: 139    step: 83\n","Episode: 140    step: 179\n","Episode: 141    step: 65\n","Loss:  50.43401\n","Episode: 142    step: 69\n","Episode: 143    step: 113\n","Episode: 144    step: 90\n","Episode: 145    step: 51\n","Episode: 146    step: 58\n","Episode: 147    step: 36\n","Episode: 148    step: 37\n","Episode: 149    step: 48\n","Episode: 150    step: 68\n","Episode: 151    step: 93\n","Loss:  0.5311047\n","Episode: 152    step: 48\n","Episode: 153    step: 107\n","Episode: 154    step: 89\n","Episode: 155    step: 70\n","Episode: 156    step: 61\n","Episode: 157    step: 36\n","Episode: 158    step: 73\n","Episode: 159    step: 56\n","Episode: 160    step: 40\n","Episode: 161    step: 110\n","Loss:  50.518402\n","Episode: 162    step: 90\n","Episode: 163    step: 143\n","Episode: 164    step: 64\n","Episode: 165    step: 42\n","Episode: 166    step: 47\n","Episode: 167    step: 58\n","Episode: 168    step: 114\n","Episode: 169    step: 45\n","Episode: 170    step: 98\n","Episode: 171    step: 32\n","Loss:  50.60992\n","Episode: 172    step: 45\n","Episode: 173    step: 30\n","Episode: 174    step: 46\n","Episode: 175    step: 62\n","Episode: 176    step: 45\n","Episode: 177    step: 67\n","Episode: 178    step: 103\n","Episode: 179    step: 58\n","Episode: 180    step: 41\n","Episode: 181    step: 119\n","Loss:  49.438587\n","Episode: 182    step: 73\n","Episode: 183    step: 47\n","Episode: 184    step: 73\n","Episode: 185    step: 38\n","Episode: 186    step: 38\n","Episode: 187    step: 94\n","Episode: 188    step: 39\n","Episode: 189    step: 81\n","Episode: 190    step: 62\n","Episode: 191    step: 45\n","Loss:  50.61531\n","Episode: 192    step: 96\n","Episode: 193    step: 120\n","Episode: 194    step: 35\n","Episode: 195    step: 31\n","Episode: 196    step: 105\n","Episode: 197    step: 71\n","Episode: 198    step: 68\n","Episode: 199    step: 44\n","Episode: 200    step: 111\n","Episode: 201    step: 46\n","Loss:  50.86387\n","Episode: 202    step: 66\n","Episode: 203    step: 97\n","Episode: 204    step: 33\n","Episode: 205    step: 37\n","Episode: 206    step: 59\n","Episode: 207    step: 101\n","Episode: 208    step: 104\n","Episode: 209    step: 75\n","Episode: 210    step: 27\n","Episode: 211    step: 37\n","Loss:  0.6838158\n","Episode: 212    step: 41\n","Episode: 213    step: 80\n","Episode: 214    step: 43\n","Episode: 215    step: 44\n","Episode: 216    step: 50\n","Episode: 217    step: 89\n","Episode: 218    step: 87\n","Episode: 219    step: 29\n","Episode: 220    step: 57\n","Episode: 221    step: 80\n","Loss:  0.65496093\n","Episode: 222    step: 48\n","Episode: 223    step: 54\n","Episode: 224    step: 51\n","Episode: 225    step: 43\n","Episode: 226    step: 38\n","Episode: 227    step: 142\n","Episode: 228    step: 90\n","Episode: 229    step: 68\n","Episode: 230    step: 97\n","Episode: 231    step: 30\n","Loss:  151.26804\n","Episode: 232    step: 41\n","Episode: 233    step: 55\n","Episode: 234    step: 47\n","Episode: 235    step: 35\n","Episode: 236    step: 42\n","Episode: 237    step: 69\n","Episode: 238    step: 51\n","Episode: 239    step: 61\n","Episode: 240    step: 56\n","Episode: 241    step: 34\n","Loss:  0.58719045\n","Episode: 242    step: 43\n","Episode: 243    step: 61\n","Episode: 244    step: 30\n","Episode: 245    step: 31\n","Episode: 246    step: 27\n","Episode: 247    step: 29\n","Episode: 248    step: 39\n","Episode: 249    step: 66\n","Episode: 250    step: 68\n","Episode: 251    step: 47\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-20a4c88e53ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-b750c2d231f5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0;31m# Minibatch works better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mminibatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_replay_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-ba5f80307d80>\u001b[0m in \u001b[0;36msimple_replay_train\u001b[0;34m(DQN, train_batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdis\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-4a2b26f9eb05>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Qpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"YE6csOT4q-Op","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}