{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab10-1_MNIST-with-tf.nn.relu.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xGOxm78IZY5Y","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import random\n","import timeit\n","\n","from tensorflow.examples.tutorials.mnist import input_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"21A36L8XfUUk","colab_type":"code","outputId":"8411088c-1144-406c-982f-045846891238","executionInfo":{"status":"ok","timestamp":1558241013754,"user_tz":-540,"elapsed":2874,"user":{"displayName":"Hong Hong","photoUrl":"","userId":"17352177631675721232"}},"colab":{"base_uri":"https://localhost:8080/","height":502}},"source":["mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n","\n","\n","x = tf.placeholder(tf.float32, [None, 784], name = 'input')\n","y = tf.placeholder(tf.float32, [None, 10], name = 'label')\n","  \n","  \n","with tf.name_scope('Layer1'):\n","  w1 = tf.Variable(tf.random_normal([784, 60]), name='w1')\n","  b1 = tf.Variable(tf.random_normal([60]), name='b1')\n","  L1 = tf.nn.relu(tf.matmul(x, w1)+b1)\n","\n","  # Tensorboard\n","  tf.summary.histogram('weight1', w1)\n","  tf.summary.histogram('bias1', b1)\n","  tf.summary.histogram('Layer1', L1)\n","\n","with tf.name_scope('Layer2'):\n","  w2 = tf.Variable(tf.random_normal([60, 10]), name='w2')\n","  b2 = tf.Variable(tf.random_normal([10]), name='b2')\n","  hypothesis = tf.nn.relu(tf.matmul(L1, w2)+b2)\n","\n","  # Tensorboard\n","  tf.summary.histogram('weight1', w1)\n","  tf.summary.histogram('bias1', b1)\n","  tf.summary.histogram('Layer1', L1)\n","  \n","with tf.name_scope('Cost'):\n","  cost = tf.reduce_mean(\n","              tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis,\n","                                                         labels=y))\n","  tf.summary.scalar('cost', cost)\n","    \n","with tf.name_scope('Train'):\n","  train = tf.train.AdamOptimizer(0.01).minimize(cost)\n","  \n","compare_prediction = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(y, axis=1))\n","accuracy = tf.reduce_mean(tf.cast(compare_prediction, tf.float32))\n","tf.summary.scalar('accuracy', accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-a8920ddd318f>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'accuracy:0' shape=() dtype=string>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"fMS4MXLffYDw","colab_type":"code","colab":{}},"source":["learing_rate = 0.001\n","batch_size = 100\n","num_epochs = 50\n","num_iterations = int(mnist.train.num_examples / batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPegvtnVfW5a","colab_type":"code","colab":{}},"source":["def run():\n","  with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n","    # Tensorboard\n","    summary = tf.summary.merge_all()\n","    writer = tf.summary.FileWriter(\"./logs/Lab10-01\")\n","    writer.add_graph(sess.graph)\n","\n","    sess.run(tf.global_variables_initializer())\n","    for epoch in range(num_epochs):\n","      avg_cost = 0\n","\n","      for iteration in range(num_iterations):\n","        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","        feed_dict = {x:batch_xs, y:batch_ys}\n","\n","\n","        _, cost_val, summary_val = sess.run([train, cost, summary], feed_dict = feed_dict)\n","\n","        writer.add_summary(summary_val, global_step = iteration)\n","        avg_cost += cost_val / num_iterations\n","\n","      print(\"Epoch: {:04d}\\nCost: {:.9f}\\n\".format(epoch+1, avg_cost))\n","    print(\"Learning Finished!\")\n","\n","    # Test\n","    print(\n","          \"Accuracy:\",\n","          sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}),\n","      )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OuMN3rJ3W8Mn","colab_type":"code","outputId":"ba2a6ae5-60a7-4fea-dee3-dbe8f18a8748","executionInfo":{"status":"ok","timestamp":1558241014491,"user_tz":-540,"elapsed":3541,"user":{"displayName":"Hong Hong","photoUrl":"","userId":"17352177631675721232"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.test.is_gpu_available()\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"6blXH8gsQZOG","colab_type":"code","outputId":"228360e0-d5f8-43ce-9311-ceb5a8b07aa3","executionInfo":{"status":"ok","timestamp":1558241330088,"user_tz":-540,"elapsed":319125,"user":{"displayName":"Hong Hong","photoUrl":"","userId":"17352177631675721232"}},"colab":{"base_uri":"https://localhost:8080/","height":5474}},"source":["time = timeit.timeit('run()', number = 2, setup='from __main__ import run')\n","\n","print(time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0001\n","Cost: 2.969393724\n","\n","Epoch: 0002\n","Cost: 1.686201945\n","\n","Epoch: 0003\n","Cost: 1.543599920\n","\n","Epoch: 0004\n","Cost: 1.354275031\n","\n","Epoch: 0005\n","Cost: 1.244484206\n","\n","Epoch: 0006\n","Cost: 1.189061245\n","\n","Epoch: 0007\n","Cost: 1.142213477\n","\n","Epoch: 0008\n","Cost: 1.111764261\n","\n","Epoch: 0009\n","Cost: 1.099952939\n","\n","Epoch: 0010\n","Cost: 1.074254260\n","\n","Epoch: 0011\n","Cost: 1.062496375\n","\n","Epoch: 0012\n","Cost: 1.057064893\n","\n","Epoch: 0013\n","Cost: 1.053733063\n","\n","Epoch: 0014\n","Cost: 1.040672853\n","\n","Epoch: 0015\n","Cost: 1.036974327\n","\n","Epoch: 0016\n","Cost: 1.018067436\n","\n","Epoch: 0017\n","Cost: 1.021647113\n","\n","Epoch: 0018\n","Cost: 1.015888000\n","\n","Epoch: 0019\n","Cost: 1.013243538\n","\n","Epoch: 0020\n","Cost: 1.010800423\n","\n","Epoch: 0021\n","Cost: 1.004888314\n","\n","Epoch: 0022\n","Cost: 1.004684711\n","\n","Epoch: 0023\n","Cost: 1.007367400\n","\n","Epoch: 0024\n","Cost: 1.000269789\n","\n","Epoch: 0025\n","Cost: 1.002741504\n","\n","Epoch: 0026\n","Cost: 0.995646956\n","\n","Epoch: 0027\n","Cost: 0.993107722\n","\n","Epoch: 0028\n","Cost: 0.990071381\n","\n","Epoch: 0029\n","Cost: 1.000490080\n","\n","Epoch: 0030\n","Cost: 0.994578591\n","\n","Epoch: 0031\n","Cost: 0.982917726\n","\n","Epoch: 0032\n","Cost: 0.936727727\n","\n","Epoch: 0033\n","Cost: 0.877170992\n","\n","Epoch: 0034\n","Cost: 0.846880084\n","\n","Epoch: 0035\n","Cost: 0.824390361\n","\n","Epoch: 0036\n","Cost: 0.820378797\n","\n","Epoch: 0037\n","Cost: 0.809069697\n","\n","Epoch: 0038\n","Cost: 0.791604026\n","\n","Epoch: 0039\n","Cost: 0.799402715\n","\n","Epoch: 0040\n","Cost: 0.789712686\n","\n","Epoch: 0041\n","Cost: 0.784670078\n","\n","Epoch: 0042\n","Cost: 0.785738590\n","\n","Epoch: 0043\n","Cost: 0.728293861\n","\n","Epoch: 0044\n","Cost: 0.670671933\n","\n","Epoch: 0045\n","Cost: 0.636710741\n","\n","Epoch: 0046\n","Cost: 0.616478267\n","\n","Epoch: 0047\n","Cost: 0.610196809\n","\n","Epoch: 0048\n","Cost: 0.606811999\n","\n","Epoch: 0049\n","Cost: 0.601994294\n","\n","Epoch: 0050\n","Cost: 0.595720460\n","\n","Learning Finished!\n","Accuracy: 0.7498\n","Epoch: 0001\n","Cost: 2.712813527\n","\n","Epoch: 0002\n","Cost: 1.564517383\n","\n","Epoch: 0003\n","Cost: 1.349153791\n","\n","Epoch: 0004\n","Cost: 1.091514003\n","\n","Epoch: 0005\n","Cost: 0.973475205\n","\n","Epoch: 0006\n","Cost: 0.858145846\n","\n","Epoch: 0007\n","Cost: 0.780036464\n","\n","Epoch: 0008\n","Cost: 0.734033806\n","\n","Epoch: 0009\n","Cost: 0.702133273\n","\n","Epoch: 0010\n","Cost: 0.668147545\n","\n","Epoch: 0011\n","Cost: 0.656172815\n","\n","Epoch: 0012\n","Cost: 0.634539868\n","\n","Epoch: 0013\n","Cost: 0.619538022\n","\n","Epoch: 0014\n","Cost: 0.606261951\n","\n","Epoch: 0015\n","Cost: 0.598617381\n","\n","Epoch: 0016\n","Cost: 0.592338713\n","\n","Epoch: 0017\n","Cost: 0.591469806\n","\n","Epoch: 0018\n","Cost: 0.583600168\n","\n","Epoch: 0019\n","Cost: 0.579363507\n","\n","Epoch: 0020\n","Cost: 0.572203128\n","\n","Epoch: 0021\n","Cost: 0.571096312\n","\n","Epoch: 0022\n","Cost: 0.570197823\n","\n","Epoch: 0023\n","Cost: 0.569289839\n","\n","Epoch: 0024\n","Cost: 0.556742964\n","\n","Epoch: 0025\n","Cost: 0.562256431\n","\n","Epoch: 0026\n","Cost: 0.560267295\n","\n","Epoch: 0027\n","Cost: 0.557343386\n","\n","Epoch: 0028\n","Cost: 0.550956328\n","\n","Epoch: 0029\n","Cost: 0.551821311\n","\n","Epoch: 0030\n","Cost: 0.557814145\n","\n","Epoch: 0031\n","Cost: 0.548701814\n","\n","Epoch: 0032\n","Cost: 0.548286162\n","\n","Epoch: 0033\n","Cost: 0.549726972\n","\n","Epoch: 0034\n","Cost: 0.554542863\n","\n","Epoch: 0035\n","Cost: 0.550608933\n","\n","Epoch: 0036\n","Cost: 0.543808983\n","\n","Epoch: 0037\n","Cost: 0.544892607\n","\n","Epoch: 0038\n","Cost: 0.539673217\n","\n","Epoch: 0039\n","Cost: 0.543132160\n","\n","Epoch: 0040\n","Cost: 0.541534806\n","\n","Epoch: 0041\n","Cost: 0.547361981\n","\n","Epoch: 0042\n","Cost: 0.535755477\n","\n","Epoch: 0043\n","Cost: 0.548966923\n","\n","Epoch: 0044\n","Cost: 0.540596642\n","\n","Epoch: 0045\n","Cost: 0.545098847\n","\n","Epoch: 0046\n","Cost: 0.535677235\n","\n","Epoch: 0047\n","Cost: 0.538931267\n","\n","Epoch: 0048\n","Cost: 0.539076077\n","\n","Epoch: 0049\n","Cost: 0.536745720\n","\n","Epoch: 0050\n","Cost: 0.533751022\n","\n","Learning Finished!\n","Accuracy: 0.7574\n","315.580853146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sZT2Tc6PVXhP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}